---
phase: 08-global-state
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified: [src/context/pin_extractor.py, src/context/__init__.py]
autonomous: true
---

<objective>
Build pin ingestion and pinned-to-constraints extractor for Layer 2 (Channel Knowledge).

Purpose: Convert pinned Slack messages into structured channel rules (naming conventions, DoD, API rules).
Output: `PinExtractor` class that fetches pins, hashes them, and extracts structured knowledge via LLM.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-global-state/08-CONTEXT.md
@.planning/phases/08-global-state/08-01-SUMMARY.md

@src/db/models.py
@src/db/channel_context_store.py
@src/llm/client.py
@src/slack/app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PinExtractor class</name>
  <files>src/context/pin_extractor.py, src/context/__init__.py</files>
  <action>
Create `src/context/__init__.py` (empty package) and `src/context/pin_extractor.py`:

```python
"""Pin content extraction and processing for Channel Knowledge layer."""
import hashlib
import logging
from dataclasses import dataclass
from typing import Optional

from slack_sdk import WebClient

from src.db.models import ChannelKnowledge

logger = logging.getLogger(__name__)


@dataclass
class PinInfo:
    """Metadata about a pinned message."""
    pin_id: str  # Usually message_ts
    message_ts: str
    text: str
    user_id: str
    pinned_at: Optional[str] = None


class PinExtractor:
    """Extracts and processes pinned messages for channel knowledge.

    Usage:
        extractor = PinExtractor(slack_client)
        pins = await extractor.fetch_pins(channel_id)
        digest = extractor.compute_digest(pins)
        if digest != stored_digest:
            knowledge = await extractor.extract_knowledge(pins)
    """

    def __init__(self, client: WebClient) -> None:
        self._client = client

    async def fetch_pins(self, channel_id: str) -> list[PinInfo]:
        """Fetch all pinned messages for a channel.

        Returns:
            List of PinInfo objects sorted by pinned_at (oldest first).
        """
        # Use pins.list API
        # Handle pagination if > 100 pins (rare)
        # Return list of PinInfo

    def compute_digest(self, pins: list[PinInfo]) -> str:
        """Compute SHA256 hash of pin IDs + message_ts.

        Used for change detection - if digest unchanged, skip re-extraction.

        Args:
            pins: List of PinInfo objects.

        Returns:
            SHA256 hex digest (first 16 chars for readability).
        """
        content = "|".join(f"{p.pin_id}:{p.message_ts}" for p in sorted(pins, key=lambda x: x.pin_id))
        return hashlib.sha256(content.encode()).hexdigest()[:16]

    async def extract_knowledge(self, pins: list[PinInfo]) -> ChannelKnowledge:
        """Extract structured knowledge from pinned content using LLM.

        Looks for:
        - naming_convention: How to name tickets/branches
        - definition_of_done: What makes a ticket complete
        - api_format_rules: API conventions (timestamp format, etc.)
        - custom_rules: Other extracted rules

        Args:
            pins: List of PinInfo objects with text content.

        Returns:
            ChannelKnowledge with extracted rules.
        """
        # Combine pin texts
        # Call LLM with extraction prompt
        # Parse response into ChannelKnowledge fields
        # If LLM fails, return empty knowledge with source_pin_ids set
```

Key implementation details:
1. `fetch_pins()`: Use `self._client.pins_list(channel=channel_id)`. Filter for message pins (not file pins). Handle rate limits gracefully.
2. `compute_digest()`: Sort pins before hashing for deterministic output.
3. `extract_knowledge()`: Use simple structured prompt asking LLM to identify rules. Parse JSON response. If extraction fails, log and return empty ChannelKnowledge.
  </action>
  <verify>python -c "from src.context.pin_extractor import PinExtractor, PinInfo; print('ok')"</verify>
  <done>PinExtractor class with fetch_pins, compute_digest, extract_knowledge methods</done>
</task>

<task type="auto">
  <name>Task 2: Add pin refresh logic to ChannelContextStore</name>
  <files>src/db/channel_context_store.py</files>
  <action>
Add helper method for checking staleness:

```python
async def needs_pin_refresh(self, team_id: str, channel_id: str, current_digest: str) -> bool:
    """Check if pins need re-extraction based on digest.

    Args:
        team_id: Slack team ID.
        channel_id: Slack channel ID.
        current_digest: Digest computed from current pins.

    Returns:
        True if digest changed or context doesn't exist.
    """
    ctx = await self.get_by_channel(team_id, channel_id)
    if not ctx:
        return True
    return ctx.pinned_digest != current_digest
```

Also add `is_stale_pin` check based on age:

```python
def is_stale_knowledge(self, ctx: ChannelContext, stale_months: int = 3) -> bool:
    """Check if pinned knowledge might be stale.

    Args:
        ctx: Channel context.
        stale_months: How many months before suggesting refresh.

    Returns:
        True if knowledge last updated > stale_months ago.
    """
    if not ctx.knowledge.source_pin_ids:
        return False  # No knowledge to be stale
    if not ctx.updated_at:
        return True
    age = datetime.now(timezone.utc) - ctx.updated_at
    return age.days > (stale_months * 30)
```
  </action>
  <verify>python -c "from src.db.channel_context_store import ChannelContextStore; import inspect; print('needs_pin_refresh' in dir(ChannelContextStore))"</verify>
  <done>ChannelContextStore has needs_pin_refresh and is_stale_knowledge methods</done>
</task>

<task type="auto">
  <name>Task 3: Create LLM prompt for knowledge extraction</name>
  <files>src/context/pin_extractor.py</files>
  <action>
Add extraction prompt and LLM call implementation:

```python
EXTRACTION_PROMPT = """Analyze these pinned messages from a Slack channel and extract any team rules or conventions.

PINNED MESSAGES:
{pin_content}

Extract the following if present (leave null if not found):
- naming_convention: How the team names things (tickets, branches, PRs)
- definition_of_done: What makes work complete
- api_format_rules: API conventions (date formats, field naming, etc.)
- custom_rules: Any other rules or conventions mentioned

Respond in JSON format:
{{
  "naming_convention": "string or null",
  "definition_of_done": "string or null",
  "api_format_rules": "string or null",
  "custom_rules": {{"rule_name": "rule_description"}}
}}

Only extract explicit rules. Don't infer or guess."""


async def extract_knowledge(self, pins: list[PinInfo]) -> ChannelKnowledge:
    """Extract structured knowledge from pinned content using LLM."""
    if not pins:
        return ChannelKnowledge(source_pin_ids=[])

    # Combine pin texts (limit to reasonable size)
    pin_content = "\n\n---\n\n".join(
        f"[Pin {i+1}] {p.text[:2000]}"  # Truncate long pins
        for i, p in enumerate(pins[:10])  # Max 10 pins
    )

    from src.llm.client import get_llm

    try:
        llm = get_llm()
        prompt = EXTRACTION_PROMPT.format(pin_content=pin_content)
        result = await llm.invoke(prompt)

        # Parse JSON response
        import json
        data = json.loads(result.content)

        return ChannelKnowledge(
            naming_convention=data.get("naming_convention"),
            definition_of_done=data.get("definition_of_done"),
            api_format_rules=data.get("api_format_rules"),
            custom_rules=data.get("custom_rules", {}),
            source_pin_ids=[p.pin_id for p in pins],
        )
    except Exception as e:
        logger.warning(f"Knowledge extraction failed: {e}")
        return ChannelKnowledge(source_pin_ids=[p.pin_id for p in pins])
```
  </action>
  <verify>python -c "from src.context.pin_extractor import EXTRACTION_PROMPT; print('ok')"</verify>
  <done>LLM-based knowledge extraction with graceful fallback</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.context.pin_extractor import PinExtractor, PinInfo"` succeeds
- [ ] `python -c "from src.context import PinExtractor"` succeeds
- [ ] PinExtractor has fetch_pins, compute_digest, extract_knowledge methods
- [ ] ChannelContextStore has needs_pin_refresh method
- [ ] EXTRACTION_PROMPT defined for LLM knowledge extraction
</verification>

<success_criteria>

- PinExtractor fetches pins from Slack API
- Digest computation enables change detection
- LLM extracts naming_convention, definition_of_done, api_format_rules
- Graceful fallback if LLM fails
- ChannelContextStore can check if pins need refresh
</success_criteria>

<output>
After completion, create `.planning/phases/08-global-state/08-02-SUMMARY.md`
</output>
