---
phase: 08-global-state
plan: 03
type: execute
wave: 2
depends_on: ["08-01"]
files_modified: [src/context/root_indexer.py, src/db/root_index_store.py, src/db/__init__.py]
autonomous: true
---

<objective>
Build root message indexer that catalogs thread topics and links them to epics/tickets.

Purpose: Index: root_ts → epic_id → ticket_keys with 30-90 day retention window.
Output: `RootIndexer` class and `RootIndexStore` for tracking thread origins.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-global-state/08-CONTEXT.md
@.planning/phases/08-global-state/08-01-SUMMARY.md

@src/db/models.py
@src/db/session_store.py
@src/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create RootIndex model and RootIndexStore</name>
  <files>src/db/models.py, src/db/root_index_store.py, src/db/__init__.py</files>
  <action>
1. Add to src/db/models.py:

```python
class RootIndex(BaseModel):
    """Index entry for a root message (thread starter).

    Maps: channel_id + root_ts -> epic_id -> ticket_keys
    Used for channel activity snapshot and context.
    """
    id: str = Field(description="UUID")
    team_id: str
    channel_id: str
    root_ts: str = Field(description="Thread root message timestamp")
    text_summary: Optional[str] = Field(default=None, description="Brief summary of root topic (max 100 chars)")
    entities: list[str] = Field(default_factory=list, description="Extracted entities/tags")
    epic_id: Optional[str] = None
    ticket_keys: list[str] = Field(default_factory=list)
    is_pinned: bool = Field(default=False, description="Pinned threads live beyond retention window")
    created_at: datetime
    updated_at: datetime
```

2. Create src/db/root_index_store.py:

```python
"""Root message index store for channel activity tracking."""
import uuid
from datetime import datetime, timezone, timedelta
from typing import Optional

from psycopg import AsyncConnection

from src.db.models import RootIndex
from src.config.settings import get_settings


class RootIndexStore:
    """Async CRUD for root message index.

    Usage:
        async with get_connection() as conn:
            store = RootIndexStore(conn)
            await store.index_root(team_id, channel_id, root_ts, text_summary)
    """

    def __init__(self, conn: AsyncConnection) -> None:
        self._conn = conn

    async def create_tables(self) -> None:
        """Create root_index table."""
        # CREATE TABLE IF NOT EXISTS root_index (
        #   id UUID PRIMARY KEY,
        #   team_id TEXT NOT NULL,
        #   channel_id TEXT NOT NULL,
        #   root_ts TEXT NOT NULL,
        #   text_summary TEXT,
        #   entities JSONB DEFAULT '[]',
        #   epic_id TEXT,
        #   ticket_keys JSONB DEFAULT '[]',
        #   is_pinned BOOLEAN DEFAULT FALSE,
        #   created_at TIMESTAMPTZ DEFAULT NOW(),
        #   updated_at TIMESTAMPTZ DEFAULT NOW(),
        #   UNIQUE(team_id, channel_id, root_ts)
        # )
        # CREATE INDEX idx_root_channel ON root_index(team_id, channel_id, created_at DESC);

    async def index_root(
        self,
        team_id: str,
        channel_id: str,
        root_ts: str,
        text_summary: Optional[str] = None,
        entities: list[str] = None,
    ) -> RootIndex:
        """Add or update root index entry."""
        # ON CONFLICT (team_id, channel_id, root_ts) DO UPDATE

    async def link_epic(self, team_id: str, channel_id: str, root_ts: str, epic_id: str) -> RootIndex:
        """Link root to an epic."""

    async def add_ticket(self, team_id: str, channel_id: str, root_ts: str, ticket_key: str) -> RootIndex:
        """Add ticket key to root's ticket_keys array."""

    async def mark_pinned(self, team_id: str, channel_id: str, root_ts: str, is_pinned: bool) -> None:
        """Mark root as pinned (lives beyond retention)."""

    async def get_recent_roots(
        self,
        team_id: str,
        channel_id: str,
        window_days: Optional[int] = None,
        limit: int = 50,
    ) -> list[RootIndex]:
        """Get recent roots within retention window.

        Includes:
        - All roots within window_days
        - All pinned roots regardless of age
        """
        settings = get_settings()
        window = window_days or settings.channel_context_root_window_days
        cutoff = datetime.now(timezone.utc) - timedelta(days=window)
        # SELECT * WHERE (created_at >= cutoff OR is_pinned = TRUE)
        # ORDER BY created_at DESC LIMIT limit

    async def get_roots_by_epic(self, team_id: str, epic_id: str) -> list[RootIndex]:
        """Get all roots linked to an epic."""

    async def cleanup_old_roots(self, team_id: str, channel_id: str, window_days: int) -> int:
        """Delete non-pinned roots older than window. Return count deleted."""
```

3. Update src/db/__init__.py:
```python
from src.db.root_index_store import RootIndexStore
from src.db.models import RootIndex
```
  </action>
  <verify>python -c "from src.db.root_index_store import RootIndexStore; from src.db.models import RootIndex; print('ok')"</verify>
  <done>RootIndex model and RootIndexStore with all CRUD methods</done>
</task>

<task type="auto">
  <name>Task 2: Create RootIndexer for automatic indexing</name>
  <files>src/context/root_indexer.py, src/context/__init__.py</files>
  <action>
Create src/context/root_indexer.py:

```python
"""Root message indexer for channel activity tracking."""
import logging
from typing import Optional

from psycopg import AsyncConnection

from src.db.root_index_store import RootIndexStore
from src.db.models import RootIndex

logger = logging.getLogger(__name__)


class RootIndexer:
    """Indexes root messages (thread starters) for channel context.

    Called when:
    - New thread detected (index root)
    - Epic bound to thread (link_epic)
    - Ticket created (add_ticket)
    """

    def __init__(self, conn: AsyncConnection) -> None:
        self._store = RootIndexStore(conn)

    async def on_new_thread(
        self,
        team_id: str,
        channel_id: str,
        root_ts: str,
        root_text: str,
    ) -> RootIndex:
        """Index a new thread's root message.

        Args:
            team_id: Slack team ID.
            channel_id: Slack channel ID.
            root_ts: Root message timestamp.
            root_text: Text of root message.

        Returns:
            Created or updated RootIndex.
        """
        # Extract summary (first 100 chars, clean)
        summary = self._extract_summary(root_text)

        # Extract entities (simple: @mentions, #channels, ticket keys)
        entities = self._extract_entities(root_text)

        return await self._store.index_root(
            team_id=team_id,
            channel_id=channel_id,
            root_ts=root_ts,
            text_summary=summary,
            entities=entities,
        )

    async def on_epic_bound(
        self,
        team_id: str,
        channel_id: str,
        root_ts: str,
        epic_id: str,
    ) -> RootIndex:
        """Update index when epic is bound to thread."""
        return await self._store.link_epic(team_id, channel_id, root_ts, epic_id)

    async def on_ticket_created(
        self,
        team_id: str,
        channel_id: str,
        root_ts: str,
        ticket_key: str,
    ) -> RootIndex:
        """Update index when ticket is created from thread."""
        return await self._store.add_ticket(team_id, channel_id, root_ts, ticket_key)

    def _extract_summary(self, text: str) -> str:
        """Extract brief summary from root text."""
        # Clean whitespace, take first 100 chars
        clean = " ".join(text.split())
        return clean[:100] + ("..." if len(clean) > 100 else "")

    def _extract_entities(self, text: str) -> list[str]:
        """Extract @mentions, #channels, PROJ-123 patterns."""
        import re
        entities = []

        # @mentions
        mentions = re.findall(r"<@(\w+)>", text)
        entities.extend([f"@{m}" for m in mentions[:5]])

        # #channels
        channels = re.findall(r"<#(\w+)\|[^>]+>", text)
        entities.extend([f"#{c}" for c in channels[:3]])

        # Ticket keys (PROJ-123)
        tickets = re.findall(r"\b([A-Z]+-\d+)\b", text)
        entities.extend(tickets[:5])

        return entities[:10]  # Max 10 entities
```

Update src/context/__init__.py:
```python
from src.context.pin_extractor import PinExtractor, PinInfo
from src.context.root_indexer import RootIndexer
```
  </action>
  <verify>python -c "from src.context.root_indexer import RootIndexer; print('ok')"</verify>
  <done>RootIndexer with on_new_thread, on_epic_bound, on_ticket_created methods</done>
</task>

<task type="auto">
  <name>Task 3: Add activity snapshot builder</name>
  <files>src/context/root_indexer.py</files>
  <action>
Add method to RootIndexer for building activity snapshot:

```python
async def build_activity_snapshot(
    self,
    team_id: str,
    channel_id: str,
) -> "ChannelActivitySnapshot":
    """Build activity snapshot from recent roots.

    Returns:
        ChannelActivitySnapshot with active_epics, recent_tickets, etc.
    """
    from datetime import datetime, timezone
    from src.db.models import ChannelActivitySnapshot

    roots = await self._store.get_recent_roots(team_id, channel_id)

    # Collect unique epics
    active_epics = list(set(
        r.epic_id for r in roots
        if r.epic_id
    ))[:10]

    # Collect recent tickets (most recent first)
    recent_tickets = []
    seen = set()
    for r in roots:
        for tk in r.ticket_keys:
            if tk not in seen:
                recent_tickets.append(tk)
                seen.add(tk)
            if len(recent_tickets) >= 10:
                break
        if len(recent_tickets) >= 10:
            break

    return ChannelActivitySnapshot(
        active_epics=active_epics,
        recent_tickets=recent_tickets,
        top_constraints=[],  # Filled by separate constraint aggregation
        unresolved_conflicts=[],  # Filled by contradiction detector
        last_updated=datetime.now(timezone.utc),
    )
```
  </action>
  <verify>python -c "from src.context.root_indexer import RootIndexer; import inspect; print('build_activity_snapshot' in [m[0] for m in inspect.getmembers(RootIndexer, predicate=inspect.isfunction)])"</verify>
  <done>RootIndexer can build ChannelActivitySnapshot from indexed roots</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.db.models import RootIndex"` succeeds
- [ ] `python -c "from src.db.root_index_store import RootIndexStore"` succeeds
- [ ] `python -c "from src.context.root_indexer import RootIndexer"` succeeds
- [ ] RootIndexStore has get_recent_roots with window_days support
- [ ] RootIndexer extracts summary and entities from root text
</verification>

<success_criteria>

- RootIndex model tracks root_ts → epic_id → ticket_keys
- RootIndexStore handles retention window (pinned roots exempt)
- RootIndexer auto-indexes new threads
- Activity snapshot built from recent roots
- Entities extracted (mentions, channels, ticket keys)
</success_criteria>

<output>
After completion, create `.planning/phases/08-global-state/08-03-SUMMARY.md`
</output>
