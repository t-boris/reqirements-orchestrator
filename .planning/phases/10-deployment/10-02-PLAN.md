# Plan: 10-02 Environment configuration

## Objective

Create environment configuration template and ensure all required settings are documented for production deployment.

## Execution Context

**Phase**: 10-deployment
**Wave**: 1 (can run in parallel with 10-01)
**Estimated scope**: Small (config documentation)

**Files to create/modify**:
- `.env.example` - Template with all required environment variables
- `src/config/settings.py` - Ensure all production settings are defined

**References**:
- Existing `.env` - Current configuration (not to be committed)
- `src/config/settings.py` - Current settings module

## Context

### Required Environment Variables (from 10-CONTEXT.md)
- **LLM**: GOOGLE_API_KEY (Gemini as default)
- **Slack**: SLACK_BOT_TOKEN, SLACK_APP_TOKEN, SLACK_SIGNING_SECRET
- **Jira**: JIRA_URL, JIRA_CLIENT_ID, JIRA_CLIENT_SECRET (or OAuth credentials)
- **Database**: DATABASE_URL (Postgres via asyncpg)
- **LangSmith**: LANGCHAIN_TRACING_V2, LANGCHAIN_API_KEY (for production debugging)
- **Zep**: ZEP_API_URL, ZEP_API_KEY (optional memory)

### Production Considerations
- Default LLM to Gemini (cheaper for production)
- LangSmith tracing enabled by default
- No Redis required (current architecture doesn't use it)

## Tasks

### Task 1: Read current settings module
First, read `src/config/settings.py` to understand current configuration.

### Task 2: Create .env.example
Create comprehensive environment template.

```bash
# .env.example
# =============================================================================
# MARO Configuration - Copy to .env and fill in values
# =============================================================================

# -----------------------------------------------------------------------------
# LLM Configuration (Required: at least one provider)
# -----------------------------------------------------------------------------
# Gemini (recommended for production - lower cost)
GOOGLE_API_KEY=your-google-api-key

# OpenAI (optional)
OPENAI_API_KEY=your-openai-api-key

# Anthropic (optional)
ANTHROPIC_API_KEY=your-anthropic-api-key

# Default model (gemini-1.5-flash, gpt-4o-mini, claude-3-haiku-20240307)
DEFAULT_LLM_MODEL=gemini-1.5-flash

# -----------------------------------------------------------------------------
# Slack Configuration (Required)
# -----------------------------------------------------------------------------
# Bot token (xoxb-...)
SLACK_BOT_TOKEN=xoxb-your-bot-token

# App-level token for Socket Mode (xapp-...)
SLACK_APP_TOKEN=xapp-your-app-token

# Signing secret from Slack app settings
SLACK_SIGNING_SECRET=your-signing-secret

# -----------------------------------------------------------------------------
# Jira Configuration (Required for ticket creation)
# -----------------------------------------------------------------------------
# Jira instance URL
JIRA_URL=https://your-domain.atlassian.net

# OAuth 2.0 credentials
JIRA_CLIENT_ID=your-client-id
JIRA_CLIENT_SECRET=your-client-secret

# Default project key
JIRA_PROJECT_KEY=PROJ

# -----------------------------------------------------------------------------
# Database Configuration (Required)
# -----------------------------------------------------------------------------
# PostgreSQL connection string (Docker internal: postgres container)
DATABASE_URL=postgresql+asyncpg://maro:maro_secure@postgres:5432/maro

# For docker-compose - postgres password
POSTGRES_PASSWORD=maro_secure

# -----------------------------------------------------------------------------
# LangSmith Tracing (Recommended for production debugging)
# -----------------------------------------------------------------------------
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=maro-production

# -----------------------------------------------------------------------------
# Zep Memory (Optional - semantic search for conversations)
# -----------------------------------------------------------------------------
# ZEP_API_URL=https://api.getzep.com
# ZEP_API_KEY=your-zep-api-key

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
```

### Task 3: Update settings.py if needed
Ensure settings module has all required fields with sensible defaults.

## Verification

```bash
# Check .env.example exists
cat .env.example

# Verify settings can load (dry run)
python -c "from src.config import get_settings; s = get_settings(); print(f'Default LLM: {s.default_llm_model}')"
```

## Success Criteria

- [ ] `.env.example` documents all required environment variables
- [ ] Comments explain each setting's purpose
- [ ] Sensible defaults for optional settings
- [ ] Settings module loads without error when .env is configured

## Output

Files created:
- `.env.example`
