---
phase: 20-brain-refactor
plan: 11
type: execute
wave: 6
depends_on: ["20-09", "20-10"]
files_modified:
  - src/schemas/state.py
  - src/db/fact_store.py
  - src/db/__init__.py
autonomous: true
---

<objective>
Implement structured salient_facts with Fact TypedDict: type/scope/confidence/canonical_id.

Purpose: Context persistence across conversations with dedup and eviction.
Output: Fact TypedDict, FactStore with eviction policy, AgentState integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/20-brain-refactor/20-CONTEXT.md
@src/schemas/state.py
@src/db/channel_context_store.py
</context>

<tasks>
<task type="auto">
  <name>Task 1: Add Fact TypedDict to state.py</name>
  <files>src/schemas/state.py</files>
  <action>
Add Fact TypedDict with all fields from 20-CONTEXT.md:

```python
class Fact(TypedDict):
    """Structured salient fact for context persistence.

    Facts are decisions, constraints, or assumptions extracted from conversation.
    Includes confidence for dedup/contradiction detection.
    """
    type: Literal["decision", "constraint", "assumption"]
    scope: Literal["channel", "epic", "thread"]
    source_ts: str  # Slack message timestamp
    text: str  # The fact content
    confidence: float  # 0.0 - 1.0, for ranking/eviction
    canonical_id: str  # hash(text + scope + type) for dedup


# Eviction limits per scope
FACT_LIMITS = {
    "thread": 50,
    "epic": 200,
    "channel": 300,
}
```

Add to AgentState:
```python
    # Context persistence (Phase 20)
    salient_facts: list[Fact]  # Structured facts with confidence + canonical_id
```
  </action>
  <verify>python -c "from src.schemas.state import Fact, FACT_LIMITS; print(Fact.__annotations__)"</verify>
  <done>Fact TypedDict with type, scope, source_ts, text, confidence, canonical_id</done>
</task>

<task type="auto">
  <name>Task 2: Create FactStore with eviction</name>
  <files>src/db/fact_store.py</files>
  <action>
Create new file `src/db/fact_store.py`:

```python
"""Fact store for context persistence.

Stores structured facts with eviction policy:
- Max facts per scope: thread=50, epic=200, channel=300
- Eviction by LRU or lowest confidence
- Merge by canonical_id (update instead of append)
"""
import hashlib
import logging
from typing import Optional

from asyncpg import Connection

from src.schemas.state import Fact, FACT_LIMITS

logger = logging.getLogger(__name__)


def compute_canonical_id(text: str, scope: str, fact_type: str) -> str:
    """Compute canonical ID for fact deduplication.

    Hash of normalized text + scope + type.
    """
    # Normalize text (lowercase, strip whitespace)
    normalized = f"{text.lower().strip()}:{scope}:{fact_type}"
    return hashlib.sha256(normalized.encode()).hexdigest()[:16]


class FactStore:
    """Store for structured facts with eviction."""

    def __init__(self, conn: Connection):
        self.conn = conn

    async def ensure_table(self) -> None:
        """Create facts table if not exists."""
        await self.conn.execute('''
            CREATE TABLE IF NOT EXISTS salient_facts (
                canonical_id TEXT PRIMARY KEY,
                team_id TEXT NOT NULL,
                scope_type TEXT NOT NULL,
                scope_id TEXT NOT NULL,
                fact_type TEXT NOT NULL,
                source_ts TEXT,
                text TEXT NOT NULL,
                confidence REAL DEFAULT 0.8,
                created_at TIMESTAMPTZ DEFAULT NOW(),
                updated_at TIMESTAMPTZ DEFAULT NOW()
            )
        ''')
        await self.conn.execute('''
            CREATE INDEX IF NOT EXISTS idx_facts_scope
            ON salient_facts (team_id, scope_type, scope_id)
        ''')

    async def add_fact(
        self,
        team_id: str,
        scope_type: str,  # "thread", "epic", "channel"
        scope_id: str,    # thread_ts, epic_key, channel_id
        fact: Fact,
    ) -> bool:
        """Add or update a fact.

        Uses UPSERT - updates existing fact if canonical_id matches.
        Applies eviction if scope exceeds limit.

        Returns:
            True if fact was inserted (new), False if updated (existing)
        """
        # Compute canonical ID if not provided
        canonical_id = fact.get("canonical_id") or compute_canonical_id(
            fact["text"], scope_type, fact["type"]
        )

        # UPSERT - insert or update
        result = await self.conn.execute('''
            INSERT INTO salient_facts (
                canonical_id, team_id, scope_type, scope_id,
                fact_type, source_ts, text, confidence
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
            ON CONFLICT (canonical_id) DO UPDATE SET
                text = EXCLUDED.text,
                confidence = GREATEST(salient_facts.confidence, EXCLUDED.confidence),
                updated_at = NOW()
        ''', canonical_id, team_id, scope_type, scope_id,
            fact["type"], fact.get("source_ts"), fact["text"],
            fact.get("confidence", 0.8))

        was_insert = "INSERT" in str(result)

        # Apply eviction if over limit
        limit = FACT_LIMITS.get(scope_type, 100)
        await self._evict_if_needed(team_id, scope_type, scope_id, limit)

        return was_insert

    async def get_facts(
        self,
        team_id: str,
        scope_type: str,
        scope_id: str,
        min_confidence: float = 0.0,
    ) -> list[Fact]:
        """Get facts for scope, ordered by confidence desc."""
        rows = await self.conn.fetch('''
            SELECT canonical_id, fact_type, source_ts, text, confidence
            FROM salient_facts
            WHERE team_id = $1 AND scope_type = $2 AND scope_id = $3
                AND confidence >= $4
            ORDER BY confidence DESC, updated_at DESC
        ''', team_id, scope_type, scope_id, min_confidence)

        return [
            Fact(
                type=row["fact_type"],
                scope=scope_type,
                source_ts=row["source_ts"] or "",
                text=row["text"],
                confidence=row["confidence"],
                canonical_id=row["canonical_id"],
            )
            for row in rows
        ]

    async def _evict_if_needed(
        self,
        team_id: str,
        scope_type: str,
        scope_id: str,
        limit: int,
    ) -> int:
        """Evict oldest/lowest confidence facts if over limit.

        Strategy: Delete facts with lowest confidence first,
        then oldest if confidence tied.

        Returns:
            Number of facts evicted
        """
        # Count current facts
        count = await self.conn.fetchval('''
            SELECT COUNT(*) FROM salient_facts
            WHERE team_id = $1 AND scope_type = $2 AND scope_id = $3
        ''', team_id, scope_type, scope_id)

        if count <= limit:
            return 0

        # Delete lowest confidence/oldest facts
        to_delete = count - limit
        result = await self.conn.execute('''
            DELETE FROM salient_facts
            WHERE canonical_id IN (
                SELECT canonical_id FROM salient_facts
                WHERE team_id = $1 AND scope_type = $2 AND scope_id = $3
                ORDER BY confidence ASC, updated_at ASC
                LIMIT $4
            )
        ''', team_id, scope_type, scope_id, to_delete)

        evicted = int(result.split()[1]) if result else 0
        if evicted > 0:
            logger.info(f"Evicted {evicted} facts from {scope_type}/{scope_id}")

        return evicted
```
  </action>
  <verify>python -c "from src.db.fact_store import FactStore, compute_canonical_id; print('OK')"</verify>
  <done>FactStore with add_fact, get_facts, eviction</done>
</task>

<task type="auto">
  <name>Task 3: Export from db package and add tests</name>
  <files>src/db/__init__.py, tests/test_fact_store.py</files>
  <action>
Add FactStore to db package exports:

```python
from src.db.fact_store import FactStore, compute_canonical_id
```

Create basic unit tests:

```python
"""Tests for FactStore."""
import pytest
from src.db.fact_store import compute_canonical_id


class TestCanonicalId:
    """Tests for canonical ID computation."""

    def test_same_text_same_id(self):
        """Same text produces same ID."""
        id1 = compute_canonical_id("API uses OAuth2", "thread", "decision")
        id2 = compute_canonical_id("API uses OAuth2", "thread", "decision")
        assert id1 == id2

    def test_different_text_different_id(self):
        """Different text produces different ID."""
        id1 = compute_canonical_id("API uses OAuth2", "thread", "decision")
        id2 = compute_canonical_id("API uses JWT", "thread", "decision")
        assert id1 != id2

    def test_case_insensitive(self):
        """ID is case-insensitive."""
        id1 = compute_canonical_id("API Uses OAuth2", "thread", "decision")
        id2 = compute_canonical_id("api uses oauth2", "thread", "decision")
        assert id1 == id2

    def test_whitespace_normalized(self):
        """Whitespace is normalized."""
        id1 = compute_canonical_id("  API uses OAuth2  ", "thread", "decision")
        id2 = compute_canonical_id("API uses OAuth2", "thread", "decision")
        assert id1 == id2
```
  </action>
  <verify>python -m pytest tests/test_fact_store.py -v</verify>
  <done>FactStore exported and tests pass</done>
</task>
</tasks>

<verification>
Before declaring plan complete:
- [ ] Fact TypedDict has all required fields (type, scope, source_ts, text, confidence, canonical_id)
- [ ] FactStore add_fact uses UPSERT (merge by canonical_id)
- [ ] Eviction works for thread=50, epic=200, channel=300 limits
- [ ] `python -m pytest tests/test_fact_store.py -v` passes
- [ ] `python -m pytest tests/ -x --tb=short` passes
</verification>

<success_criteria>
- Fact TypedDict with confidence and canonical_id for dedup
- FactStore with add_fact using UPSERT
- Eviction by lowest confidence when over limit
- Limits: thread=50, epic=200, channel=300
</success_criteria>

<output>
After completion, create `.planning/phases/20-brain-refactor/20-11-SUMMARY.md`
</output>
