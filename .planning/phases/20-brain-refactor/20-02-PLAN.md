---
phase: 20-brain-refactor
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/db/event_store.py
  - src/db/__init__.py
autonomous: true
---

<objective>
Create event store for idempotency tracking (processed_event_ids).

Purpose: HA-ready event deduplication with PostgreSQL storage. Prevents duplicate button clicks and Slack retries.
Output: EventStore class with add/check/cleanup methods, 24h TTL.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/20-brain-refactor/20-CONTEXT.md
@src/db/connection.py
@src/db/listening_store.py
</context>

<tasks>
<task type="auto">
  <name>Task 1: Create EventStore class</name>
  <files>src/db/event_store.py</files>
  <action>
Create new file `src/db/event_store.py` with EventStore class:

```python
"""Event store for idempotency tracking.

Tracks processed event IDs to prevent duplicate processing.
HA-ready: uses PostgreSQL with 24h TTL.
"""
import logging
from datetime import datetime, timedelta
from typing import Optional

from asyncpg import Connection

logger = logging.getLogger(__name__)

# TTL for processed events (24 hours)
EVENT_TTL_HOURS = 24


class EventStore:
    """Store for tracking processed events.

    Key format: (team_id, event_id)
    For button clicks without stable event_id: (team_id, action_id:message_ts:user_id)
    """

    def __init__(self, conn: Connection):
        self.conn = conn

    async def ensure_table(self) -> None:
        """Create events table if not exists."""
        await self.conn.execute('''
            CREATE TABLE IF NOT EXISTS processed_events (
                team_id TEXT NOT NULL,
                event_id TEXT NOT NULL,
                processed_at TIMESTAMPTZ DEFAULT NOW(),
                PRIMARY KEY (team_id, event_id)
            )
        ''')
        # Index for cleanup query
        await self.conn.execute('''
            CREATE INDEX IF NOT EXISTS idx_processed_events_time
            ON processed_events (processed_at)
        ''')

    async def is_processed(self, team_id: str, event_id: str) -> bool:
        """Check if event was already processed.

        Args:
            team_id: Slack team/workspace ID
            event_id: Event ID (or fallback key for buttons)

        Returns:
            True if event was already processed
        """
        result = await self.conn.fetchval('''
            SELECT 1 FROM processed_events
            WHERE team_id = $1 AND event_id = $2
        ''', team_id, event_id)
        return result is not None

    async def mark_processed(self, team_id: str, event_id: str) -> bool:
        """Mark event as processed.

        Uses INSERT ... ON CONFLICT DO NOTHING for race safety.

        Args:
            team_id: Slack team/workspace ID
            event_id: Event ID (or fallback key for buttons)

        Returns:
            True if this was first processing (inserted), False if already existed
        """
        result = await self.conn.execute('''
            INSERT INTO processed_events (team_id, event_id)
            VALUES ($1, $2)
            ON CONFLICT (team_id, event_id) DO NOTHING
        ''', team_id, event_id)
        # "INSERT 0 1" means inserted, "INSERT 0 0" means conflict (already existed)
        return result == "INSERT 0 1"

    async def cleanup_old_events(self, hours: int = EVENT_TTL_HOURS) -> int:
        """Remove events older than TTL.

        Should be called periodically (e.g., hourly cron).

        Args:
            hours: TTL in hours (default 24)

        Returns:
            Number of events deleted
        """
        cutoff = datetime.utcnow() - timedelta(hours=hours)
        result = await self.conn.execute('''
            DELETE FROM processed_events
            WHERE processed_at < $1
        ''', cutoff)
        # Parse "DELETE N" to get count
        count = int(result.split()[1]) if result else 0
        if count > 0:
            logger.info(f"Cleaned up {count} old events (older than {hours}h)")
        return count


def make_button_event_id(action_id: str, message_ts: str, user_id: str) -> str:
    """Create fallback event ID for button clicks.

    Use when Slack doesn't provide stable event_id.
    Format: action_id:message_ts:user_id
    """
    return f"{action_id}:{message_ts}:{user_id}"
```

Key design decisions:
- PostgreSQL for HA (multi-instance support)
- (team_id, event_id) composite key
- 24h TTL with cleanup method
- INSERT ON CONFLICT for race-safe marking
- Helper for button fallback key
  </action>
  <verify>python -c "from src.db.event_store import EventStore, make_button_event_id; print('OK')"</verify>
  <done>EventStore class created with is_processed, mark_processed, cleanup_old_events methods</done>
</task>

<task type="auto">
  <name>Task 2: Export from db package</name>
  <files>src/db/__init__.py</files>
  <action>
Add EventStore and make_button_event_id to db package exports:

```python
from src.db.event_store import EventStore, make_button_event_id
```

Add to __all__ list if it exists.
  </action>
  <verify>python -c "from src.db import EventStore, make_button_event_id; print('OK')"</verify>
  <done>EventStore importable from src.db</done>
</task>
</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.db import EventStore, make_button_event_id"` succeeds
- [ ] EventStore has ensure_table, is_processed, mark_processed, cleanup_old_events methods
- [ ] make_button_event_id returns colon-separated string
- [ ] `python -m pytest tests/ -x --tb=short` passes
</verification>

<success_criteria>
- EventStore class created with PostgreSQL-backed storage
- 24h TTL implemented
- Race-safe INSERT ON CONFLICT pattern
- Fallback key generator for button clicks
</success_criteria>

<output>
After completion, create `.planning/phases/20-brain-refactor/20-02-SUMMARY.md`
</output>
