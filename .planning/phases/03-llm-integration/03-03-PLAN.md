---
phase: 03-llm-integration
plan: 03
type: execute
wave: 1
depends_on: []
files_modified: [src/llm/prompts.py, src/llm/__init__.py]
autonomous: true
---

<objective>
Create prompt templates and utilities for the Jira analyst agent.

Purpose: Provide reusable system prompts for requirement extraction, validation, and questioning.
Output: Prompt templates for different agent behaviors (extraction, validation, questioning).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Key context from PROJECT.md:
- Bot acts as proactive business analyst
- Drives conversations to gather complete requirements
- Never creates half-baked tickets
- Type-specific schemas: Epic, Story, Task, Bug

Agent behaviors:
1. EXTRACTION: Parse messages to extract ticket fields
2. VALIDATION: Check if ticket is complete, identify missing info
3. QUESTIONING: Generate clarifying questions for missing info
4. PREVIEW: Format ticket for user approval

@src/schemas/ticket.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create prompt templates module</name>
  <files>src/llm/prompts.py</files>
  <action>
Create prompt templates for the analyst agent behaviors.

Implementation using LangChain prompt templates:

```python
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

# System prompt for the analyst agent
ANALYST_SYSTEM_PROMPT = """You are a proactive Jira ticket analyst. Your role is to:
1. Extract requirements from conversations
2. Identify missing information
3. Ask clarifying questions until requirements are complete
4. Never create half-baked tickets

You work with these ticket types:
- Epic: High-level features or initiatives (needs: summary, description)
- Story: User-facing features (needs: summary, description, acceptance_criteria)
- Task: Technical work items (needs: summary, description)
- Bug: Defects (needs: summary, description, steps_to_reproduce, expected_behavior, actual_behavior)

Current ticket type: {ticket_type}
Current draft state:
{draft_json}

Missing fields: {missing_fields}
"""

# Extraction prompt - parse messages to update draft
EXTRACTION_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(ANALYST_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template(
        "Based on this conversation, extract and update the ticket fields:\n\n{messages}\n\n"
        "Return the updated ticket as JSON matching the {ticket_type} schema."
    ),
])

# Validation prompt - check completeness
VALIDATION_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(ANALYST_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template(
        "Review the current ticket draft and determine:\n"
        "1. Is the ticket complete enough to create in Jira?\n"
        "2. What critical information is still missing?\n"
        "3. What questions should I ask to fill the gaps?\n\n"
        "Be specific about what's missing and why it matters."
    ),
])

# Questioning prompt - generate clarifying questions
QUESTIONING_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(ANALYST_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template(
        "Generate 1-3 clarifying questions to gather the missing information.\n"
        "Questions should be:\n"
        "- Specific and actionable\n"
        "- Prioritized by importance\n"
        "- Conversational, not robotic\n\n"
        "Missing fields to address: {missing_fields}"
    ),
])
```

Also add helper function to format draft for prompts:
```python
def format_draft_for_prompt(draft: dict | None) -> str:
    if draft is None:
        return "No draft yet"
    import json
    return json.dumps(draft, indent=2, default=str)
```
  </action>
  <verify>python -c "from src.llm.prompts import EXTRACTION_PROMPT, VALIDATION_PROMPT, QUESTIONING_PROMPT; print('prompts ok')"</verify>
  <done>Prompt templates for extraction, validation, questioning available</done>
</task>

<task type="auto">
  <name>Task 2: Update llm package exports</name>
  <files>src/llm/__init__.py</files>
  <action>
Add prompt exports to src/llm/__init__.py:
- ANALYST_SYSTEM_PROMPT
- EXTRACTION_PROMPT
- VALIDATION_PROMPT
- QUESTIONING_PROMPT
- format_draft_for_prompt

Keep existing exports from 03-01 and 03-02.

Pattern: from src.llm import EXTRACTION_PROMPT
  </action>
  <verify>python -c "from src.llm import EXTRACTION_PROMPT, format_draft_for_prompt; print('exports ok')"</verify>
  <done>Prompt templates available from src.llm</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.llm import EXTRACTION_PROMPT, VALIDATION_PROMPT, QUESTIONING_PROMPT"` succeeds
- [ ] Prompts can be formatted with invoke()
- [ ] No import errors
</verification>

<success_criteria>

- All tasks completed
- Prompt templates ready for agent use
- Templates include ticket-type-specific context
- Clean imports from src.llm
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-integration/03-03-SUMMARY.md`
</output>
