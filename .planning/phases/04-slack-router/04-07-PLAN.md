---
phase: 04-slack-router
plan: 07
type: execute
wave: 1
depends_on: []
files_modified: [src/documents/__init__.py, src/documents/extractor.py, pyproject.toml]
autonomous: true
---

<objective>
Create document processing for PDF, DOCX, MD, and TXT extraction.

Purpose: Extract text from Slack attachments for entity extraction and context building.
Output: Document extractors that normalize content for LLM consumption.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-slack-router/04-CONTEXT.md

Key decisions from CONTEXT:
- Supported formats: PDF, DOCX, MD, TXT (text-extractable)
- Not included: Images/vision, link fetching (deferred)
- Extracted content feeds into entity extraction pipeline
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add document processing dependencies</name>
  <files>pyproject.toml</files>
  <action>
Add to pyproject.toml dependencies:
- "pypdf>=4.0"  # PDF extraction
- "python-docx>=1.0"  # DOCX extraction

MD and TXT don't need additional dependencies.
  </action>
  <verify>pip install -e . && python -c "import pypdf; import docx; print('doc deps ok')"</verify>
  <done>Document processing dependencies installed</done>
</task>

<task type="auto">
  <name>Task 2: Create document extractors</name>
  <files>src/documents/extractor.py</files>
  <action>
Create src/documents/extractor.py:

```python
"""Document text extraction for various formats."""

import io
import logging
from pathlib import Path
from typing import Optional

import pypdf
from docx import Document

logger = logging.getLogger(__name__)

class ExtractionError(Exception):
    """Error during document extraction."""
    pass

def extract_pdf(content: bytes) -> str:
    """Extract text from PDF bytes.

    Args:
        content: PDF file content as bytes

    Returns:
        Extracted text, pages separated by newlines
    """
    try:
        reader = pypdf.PdfReader(io.BytesIO(content))
        pages = []
        for page in reader.pages:
            text = page.extract_text()
            if text:
                pages.append(text.strip())
        return "\n\n".join(pages)
    except Exception as e:
        logger.error(f"PDF extraction failed: {e}")
        raise ExtractionError(f"Failed to extract PDF: {e}")

def extract_docx(content: bytes) -> str:
    """Extract text from DOCX bytes.

    Args:
        content: DOCX file content as bytes

    Returns:
        Extracted text, paragraphs separated by newlines
    """
    try:
        doc = Document(io.BytesIO(content))
        paragraphs = []
        for para in doc.paragraphs:
            if para.text.strip():
                paragraphs.append(para.text.strip())
        return "\n\n".join(paragraphs)
    except Exception as e:
        logger.error(f"DOCX extraction failed: {e}")
        raise ExtractionError(f"Failed to extract DOCX: {e}")

def extract_text(content: bytes, encoding: str = "utf-8") -> str:
    """Extract text from plain text file (TXT, MD).

    Args:
        content: File content as bytes
        encoding: Text encoding (default utf-8)

    Returns:
        Decoded text content
    """
    try:
        return content.decode(encoding).strip()
    except UnicodeDecodeError:
        # Try latin-1 as fallback
        try:
            return content.decode("latin-1").strip()
        except Exception as e:
            raise ExtractionError(f"Failed to decode text: {e}")

def extract_from_file(content: bytes, filename: str) -> str:
    """Extract text based on file extension.

    Args:
        content: File content as bytes
        filename: Original filename (for extension detection)

    Returns:
        Extracted text content

    Raises:
        ExtractionError: If extraction fails or format unsupported
    """
    ext = Path(filename).suffix.lower()

    if ext == ".pdf":
        return extract_pdf(content)
    elif ext == ".docx":
        return extract_docx(content)
    elif ext in (".txt", ".md", ".markdown"):
        return extract_text(content)
    else:
        raise ExtractionError(f"Unsupported file type: {ext}")

def normalize_for_llm(text: str, max_length: int = 10000) -> str:
    """Normalize extracted text for LLM consumption.

    - Removes excessive whitespace
    - Truncates if too long
    - Adds truncation marker if needed

    Args:
        text: Extracted text
        max_length: Maximum character length

    Returns:
        Normalized text
    """
    # Normalize whitespace
    lines = text.split("\n")
    cleaned = []
    for line in lines:
        stripped = " ".join(line.split())  # Normalize internal whitespace
        if stripped:
            cleaned.append(stripped)

    normalized = "\n".join(cleaned)

    # Truncate if needed
    if len(normalized) > max_length:
        normalized = normalized[:max_length - 50] + "\n\n[Document truncated...]"

    return normalized
```
  </action>
  <verify>python -c "from src.documents.extractor import extract_from_file, normalize_for_llm; print('extractor ok')"</verify>
  <done>Document extractors for PDF, DOCX, MD, TXT</done>
</task>

<task type="auto">
  <name>Task 3: Create Slack file downloader</name>
  <files>src/documents/slack.py, src/documents/__init__.py</files>
  <action>
Create src/documents/slack.py for downloading Slack attachments:

```python
"""Slack file download utilities."""

import logging
from typing import Optional
from slack_sdk.web import WebClient

from src.documents.extractor import extract_from_file, normalize_for_llm, ExtractionError

logger = logging.getLogger(__name__)

# Supported MIME types
SUPPORTED_TYPES = {
    "application/pdf": ".pdf",
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document": ".docx",
    "text/plain": ".txt",
    "text/markdown": ".md",
}

async def download_and_extract(
    client: WebClient,
    file_info: dict,
    max_length: int = 10000,
) -> Optional[str]:
    """Download Slack file and extract text content.

    Args:
        client: Slack WebClient with bot token
        file_info: File object from Slack event
        max_length: Max characters for extracted text

    Returns:
        Extracted and normalized text, or None if unsupported/failed
    """
    file_id = file_info.get("id")
    filename = file_info.get("name", "unknown")
    mimetype = file_info.get("mimetype", "")
    url_private = file_info.get("url_private")

    # Check if supported
    if mimetype not in SUPPORTED_TYPES:
        logger.debug(f"Unsupported file type: {mimetype} ({filename})")
        return None

    if not url_private:
        logger.warning(f"No download URL for file: {filename}")
        return None

    try:
        # Download file content
        response = client.files_info(file=file_id)
        file_content = client.http_client.fetch(
            url_private,
            headers={"Authorization": f"Bearer {client.token}"},
        )

        # Extract text
        text = extract_from_file(file_content.body, filename)
        normalized = normalize_for_llm(text, max_length)

        logger.info(
            f"Extracted document",
            extra={
                "filename": filename,
                "mimetype": mimetype,
                "chars": len(normalized),
            }
        )

        return normalized

    except ExtractionError as e:
        logger.warning(f"Extraction failed for {filename}: {e}")
        return None
    except Exception as e:
        logger.error(f"Download failed for {filename}: {e}")
        return None

def get_extractable_files(files: list[dict]) -> list[dict]:
    """Filter files to only extractable types.

    Args:
        files: List of file objects from Slack event

    Returns:
        Filtered list of extractable files
    """
    return [
        f for f in files
        if f.get("mimetype") in SUPPORTED_TYPES
    ]
```

Create src/documents/__init__.py:
```python
"""Document processing for Slack attachments."""

from src.documents.extractor import (
    extract_from_file,
    extract_pdf,
    extract_docx,
    extract_text,
    normalize_for_llm,
    ExtractionError,
)
from src.documents.slack import (
    download_and_extract,
    get_extractable_files,
    SUPPORTED_TYPES,
)

__all__ = [
    "extract_from_file",
    "extract_pdf",
    "extract_docx",
    "extract_text",
    "normalize_for_llm",
    "ExtractionError",
    "download_and_extract",
    "get_extractable_files",
    "SUPPORTED_TYPES",
]
```
  </action>
  <verify>python -c "from src.documents import extract_from_file, download_and_extract; print('documents package ok')"</verify>
  <done>Slack file download and extraction</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pip install -e .` succeeds with pypdf and python-docx
- [ ] `python -c "from src.documents import extract_from_file"` succeeds
- [ ] PDF, DOCX, MD, TXT extraction works
- [ ] Slack file download utility available
- [ ] No import errors
</verification>

<success_criteria>

- All tasks completed
- PDF extraction via pypdf
- DOCX extraction via python-docx
- TXT/MD direct decode
- Slack file download ready
- Normalization for LLM consumption
</success_criteria>

<output>
After completion, create `.planning/phases/04-slack-router/04-07-SUMMARY.md`
</output>
