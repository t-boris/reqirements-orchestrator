---
phase: 04-slack-router
plan: 03
type: execute
wave: 2
depends_on: ["04-01"]
files_modified: [src/slack/session.py, src/slack/dedup.py, src/db/models.py]
autonomous: true
---

<objective>
Create session model with idempotency and per-thread serialization.

Purpose: Prevent duplicate event processing and race conditions in thread sessions.
Output: Session identity management with dedupe store and locking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-slack-router/04-CONTEXT.md

Prior phases provide:
- PostgreSQL connection pool (src/db/connection.py)
- ThreadSession model (src/db/models.py)
- SessionStore with CRUD (src/db/session_store.py)

Key decisions from CONTEXT:
- Canonical identity: session_id = {team_id}:{channel_id}:{thread_ts}
- Dedupe by event_id / client_msg_id
- Per-session lock (serialize runs per thread)
- Socket Mode has retries - idempotency critical

@src/db/models.py
@src/db/session_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create session identity utilities</name>
  <files>src/slack/session.py</files>
  <action>
Create src/slack/session.py with session identity management:

```python
"""Session identity and state management for Slack threads."""

import asyncio
import logging
from dataclasses import dataclass
from typing import Optional

logger = logging.getLogger(__name__)

# Per-session locks to serialize processing
_session_locks: dict[str, asyncio.Lock] = {}

@dataclass
class SessionIdentity:
    """Canonical session identity from Slack event."""
    team_id: str
    channel_id: str
    thread_ts: str  # Thread timestamp (parent message ts)

    @property
    def session_id(self) -> str:
        """Canonical session ID: team:channel:thread_ts"""
        return f"{self.team_id}:{self.channel_id}:{self.thread_ts}"

    @classmethod
    def from_event(cls, event: dict, team_id: str) -> Optional["SessionIdentity"]:
        """Extract session identity from Slack event.

        Returns None if not a thread message (no session context).
        """
        channel_id = event.get("channel")
        # thread_ts if in thread, else ts if starting new thread
        thread_ts = event.get("thread_ts") or event.get("ts")

        if not channel_id or not thread_ts:
            return None

        return cls(
            team_id=team_id,
            channel_id=channel_id,
            thread_ts=thread_ts,
        )

def get_session_lock(session_id: str) -> asyncio.Lock:
    """Get or create lock for session.

    Ensures one run at a time per thread to prevent race conditions.
    """
    if session_id not in _session_locks:
        _session_locks[session_id] = asyncio.Lock()
    return _session_locks[session_id]

async def with_session_lock(session_id: str):
    """Async context manager for session lock.

    Usage:
        async with with_session_lock(session_id):
            # process session
    """
    lock = get_session_lock(session_id)
    async with lock:
        yield

def cleanup_session_lock(session_id: str) -> None:
    """Remove session lock when session is closed.

    Call when thread is archived or session completed.
    """
    if session_id in _session_locks:
        del _session_locks[session_id]
        logger.debug(f"Cleaned up lock for session {session_id}")
```
  </action>
  <verify>python -c "from src.slack.session import SessionIdentity, get_session_lock; print('session ok')"</verify>
  <done>Session identity with canonical ID and per-session locking</done>
</task>

<task type="auto">
  <name>Task 2: Create dedup store</name>
  <files>src/slack/dedup.py</files>
  <action>
Create src/slack/dedup.py for event deduplication:

```python
"""Event deduplication to handle Socket Mode retries."""

import logging
import time
from typing import Optional

logger = logging.getLogger(__name__)

# In-memory dedupe store with TTL
# Format: {event_key: timestamp}
_processed_events: dict[str, float] = {}

# TTL for processed events (5 minutes)
DEDUP_TTL_SECONDS = 300

def _get_event_key(event: dict) -> Optional[str]:
    """Extract unique key from event for deduplication.

    Uses event_id if available, falls back to client_msg_id or message ts.
    """
    # Prefer event_id (most reliable)
    if event_id := event.get("event_id"):
        return f"event:{event_id}"

    # Fallback to client_msg_id (for messages)
    if client_msg_id := event.get("client_msg_id"):
        return f"msg:{client_msg_id}"

    # Last resort: channel + ts
    channel = event.get("channel")
    ts = event.get("ts")
    if channel and ts:
        return f"ts:{channel}:{ts}"

    return None

def is_duplicate(event: dict) -> bool:
    """Check if event was already processed.

    Returns True if duplicate (should skip), False if new.
    """
    key = _get_event_key(event)
    if not key:
        # Can't dedupe without key, assume not duplicate
        return False

    now = time.time()

    # Clean expired entries (lazy cleanup)
    expired = [k for k, t in _processed_events.items() if now - t > DEDUP_TTL_SECONDS]
    for k in expired:
        del _processed_events[k]

    if key in _processed_events:
        logger.debug(f"Duplicate event detected: {key}")
        return True

    return False

def mark_processed(event: dict) -> None:
    """Mark event as processed.

    Call after successfully processing event.
    """
    key = _get_event_key(event)
    if key:
        _processed_events[key] = time.time()
        logger.debug(f"Marked event processed: {key}")

def clear_dedup_store() -> None:
    """Clear all entries (for testing)."""
    _processed_events.clear()
```
  </action>
  <verify>python -c "from src.slack.dedup import is_duplicate, mark_processed; print('dedup ok')"</verify>
  <done>Event deduplication with TTL cleanup</done>
</task>

<task type="auto">
  <name>Task 3: Add epic_id to ThreadSession model</name>
  <files>src/db/models.py</files>
  <action>
Update ThreadSession model in src/db/models.py to add epic binding:

Add field:
```python
epic_id: Optional[str] = None  # Linked Epic Jira key (e.g., "PROJ-50")
```

This enables Rule 1: Context Binding - every session bound to an Epic.
  </action>
  <verify>python -c "from src.db.models import ThreadSession; print('epic_id' in ThreadSession.__annotations__)"</verify>
  <done>ThreadSession has epic_id for context binding</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.slack.session import SessionIdentity"` succeeds
- [ ] `python -c "from src.slack.dedup import is_duplicate"` succeeds
- [ ] SessionIdentity.from_event() extracts canonical ID
- [ ] Dedup correctly identifies duplicate events
- [ ] ThreadSession has epic_id field
</verification>

<success_criteria>

- All tasks completed
- Session identity canonical: team:channel:thread_ts
- Per-session locks prevent race conditions
- Dedup store tracks processed events with TTL
- Epic binding field ready for context binding
</success_criteria>

<output>
After completion, create `.planning/phases/04-slack-router/04-03-SUMMARY.md`
</output>
