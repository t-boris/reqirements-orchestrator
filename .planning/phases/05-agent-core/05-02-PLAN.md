---
phase: 05-agent-core
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified: [src/graph/__init__.py, src/graph/graph.py, src/graph/nodes/__init__.py, src/graph/nodes/extraction.py]
autonomous: true
---

<objective>
Create custom LangGraph with extraction node for patch-style draft updates.

Purpose: Build the graph skeleton with loop protection and extraction capability.
Output: Compilable graph with extraction node that updates draft from messages.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-agent-core/05-CONTEXT.md
@.planning/phases/05-agent-core/05-01-SUMMARY.md

From CONTEXT.md:
- Custom graph (not prebuilt create_react_agent)
- Hybrid approach: custom graph structure, reuse Phase 3 LLM adapters
- Nodes: assistant (LLM step), tools (executor), route/condition, guards
- max_steps=10 per run
- Stop condition if state unchanged after tool call

Existing:
@src/db/checkpointer.py
@src/llm/__init__.py
@src/schemas/state.py (after 05-01)
@src/schemas/draft.py (after 05-01)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create graph package structure</name>
  <files>src/graph/__init__.py, src/graph/nodes/__init__.py</files>
  <action>
Create src/graph/__init__.py:
```python
"""LangGraph agent for PM-machine workflow.

Custom graph with extraction -> validation -> decision pipeline.
"""
from src.graph.graph import create_graph, get_compiled_graph

__all__ = ["create_graph", "get_compiled_graph"]
```

Create src/graph/nodes/__init__.py:
```python
"""Graph nodes for the PM-machine workflow."""
from src.graph.nodes.extraction import extraction_node

__all__ = ["extraction_node"]
```
  </action>
  <verify>python -c "import src.graph; import src.graph.nodes; print('packages ok')"</verify>
  <done>Graph package structure created</done>
</task>

<task type="auto">
  <name>Task 2: Create extraction node</name>
  <files>src/graph/nodes/extraction.py</files>
  <action>
Create src/graph/nodes/extraction.py with patch-style draft extraction:

```python
"""Extraction node - updates draft from conversation messages.

Patch-style: Only updates fields that have new information.
Adds evidence links for traceability.
"""
import json
import logging
from typing import Any
from langchain_core.messages import HumanMessage, AIMessage

from src.schemas.state import AgentState, AgentPhase
from src.schemas.draft import TicketDraft
from src.llm import get_llm

logger = logging.getLogger(__name__)

EXTRACTION_PROMPT = '''You are extracting requirements from a conversation to build a Jira ticket draft.

Current draft state:
{draft_json}

New message to process:
{message}

Extract any new information that should update the draft. Return a JSON object with ONLY the fields that have new information. Do not repeat existing values.

Fields you can update:
- title: Clear, concise ticket title
- problem: What problem we're solving
- proposed_solution: How we'll solve it
- acceptance_criteria: List of testable criteria (append new ones)
- constraints: List of {{key, value}} technical decisions
- dependencies: List of external dependencies
- risks: List of potential risks

Return empty object {{}} if no new information to extract.

IMPORTANT: Only extract factual information stated in the message. Do not invent or assume.

JSON response:'''

async def extraction_node(state: AgentState) -> dict[str, Any]:
    """Extract requirements from latest message and patch draft.

    - Processes only the most recent human message
    - Uses LLM to identify new information
    - Patches draft with extracted fields
    - Adds evidence link for traceability
    - Increments step_count

    Returns partial state update.
    """
    messages = state.get("messages", [])
    draft = state.get("draft") or TicketDraft()
    step_count = state.get("step_count", 0)
    thread_ts = state.get("thread_ts", "")
    channel_id = state.get("channel_id", "")

    # Find most recent human message
    latest_human = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            latest_human = msg
            break

    if not latest_human:
        logger.debug("No human message to extract from")
        return {"step_count": step_count + 1}

    message_text = latest_human.content if isinstance(latest_human.content, str) else str(latest_human.content)

    # Prepare prompt
    draft_json = draft.model_dump_json(exclude={"evidence_links", "created_at", "updated_at"})
    prompt = EXTRACTION_PROMPT.format(
        draft_json=draft_json,
        message=message_text,
    )

    # Call LLM for extraction
    try:
        llm = get_llm()
        result = await llm.chat(prompt)
        response_text = result.content.strip()

        # Parse JSON response
        # Handle markdown code blocks
        if response_text.startswith("```"):
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
            response_text = response_text.strip()

        extracted = json.loads(response_text) if response_text and response_text != "{}" else {}

        if extracted:
            logger.info(
                "Extracted fields from message",
                extra={
                    "fields": list(extracted.keys()),
                    "thread_ts": thread_ts,
                }
            )

            # Handle list fields (append, don't replace)
            list_fields = ["acceptance_criteria", "dependencies", "risks"]
            for field in list_fields:
                if field in extracted and isinstance(extracted[field], list):
                    existing = getattr(draft, field, [])
                    extracted[field] = existing + extracted[field]

            # Handle constraints specially (list of dicts)
            if "constraints" in extracted:
                from src.schemas.draft import DraftConstraint, ConstraintStatus
                existing_constraints = draft.constraints
                for c in extracted["constraints"]:
                    if isinstance(c, dict) and "key" in c and "value" in c:
                        existing_constraints.append(DraftConstraint(
                            key=c["key"],
                            value=c["value"],
                            status=ConstraintStatus.PROPOSED,
                            source_message_ts=getattr(latest_human, "id", None),
                        ))
                extracted["constraints"] = existing_constraints

            # Patch draft
            draft.patch(**{k: v for k, v in extracted.items() if k not in ["constraints"] or k == "constraints"})

            # Add evidence link
            for field in extracted.keys():
                draft.add_evidence(
                    message_ts=getattr(latest_human, "id", "") or "",
                    thread_ts=thread_ts,
                    channel_id=channel_id,
                    field_updated=field,
                    text_preview=message_text[:100],
                )
        else:
            logger.debug("No new information extracted")

    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse extraction response: {e}")
    except Exception as e:
        logger.error(f"Extraction failed: {e}")

    return {
        "draft": draft,
        "step_count": step_count + 1,
        "phase": AgentPhase.COLLECTING,  # Stay in collecting after extraction
    }
```
  </action>
  <verify>python -c "from src.graph.nodes.extraction import extraction_node; print('extraction ok')"</verify>
  <done>Extraction node with patch-style updates and evidence tracking</done>
</task>

<task type="auto">
  <name>Task 3: Create graph definition with loop guards</name>
  <files>src/graph/graph.py</files>
  <action>
Create src/graph/graph.py with custom LangGraph:

```python
"""Custom LangGraph for PM-machine workflow.

Graph structure:
  START -> extraction -> should_continue -> validation (or END)
           ^                    |
           |                    v
           +---- loop back ----+

Loop protection:
- max_steps=10 enforced via step_count
- Stops if step_count >= MAX_STEPS
"""
import logging
from typing import Literal

from langgraph.graph import StateGraph, END

from src.schemas.state import AgentState, AgentPhase
from src.graph.nodes.extraction import extraction_node
from src.db.checkpointer import get_checkpointer

logger = logging.getLogger(__name__)

MAX_STEPS = 10


def should_continue(state: AgentState) -> Literal["extraction", "validation", "end"]:
    """Router: decide next step based on state.

    Routes to:
    - "end" if max_steps reached (loop protection)
    - "validation" if draft exists and has content
    - "extraction" to continue collecting
    """
    step_count = state.get("step_count", 0)
    draft = state.get("draft")
    phase = state.get("phase", AgentPhase.COLLECTING)

    # Loop protection
    if step_count >= MAX_STEPS:
        logger.warning(f"Max steps ({MAX_STEPS}) reached, stopping")
        return "end"

    # If we have a draft with content, move to validation
    if draft and (draft.title or draft.problem):
        return "validation"

    # Continue collecting
    return "extraction"


def validation_placeholder(state: AgentState) -> dict:
    """Placeholder validation node - will be implemented in 05-03.

    For now, just logs and passes through.
    """
    logger.info("Validation placeholder - draft ready for review")
    return {"phase": AgentPhase.VALIDATING}


def create_graph() -> StateGraph:
    """Create the PM-machine workflow graph.

    Returns uncompiled StateGraph. Call .compile() with checkpointer.
    """
    # Create graph with AgentState
    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("extraction", extraction_node)
    workflow.add_node("validation", validation_placeholder)

    # Set entry point
    workflow.set_entry_point("extraction")

    # Add conditional edges from extraction
    workflow.add_conditional_edges(
        "extraction",
        should_continue,
        {
            "extraction": "extraction",  # Loop back for more extraction
            "validation": "validation",  # Move to validation
            "end": END,  # Stop (max steps)
        }
    )

    # Validation goes to END for now (decision node added in 05-03)
    workflow.add_edge("validation", END)

    return workflow


def get_compiled_graph():
    """Get compiled graph with PostgreSQL checkpointer.

    Use this for production - enables interrupt/resume.
    """
    workflow = create_graph()
    checkpointer = get_checkpointer()
    return workflow.compile(checkpointer=checkpointer)


# Convenience: graph without checkpointer for testing
def get_graph_for_testing():
    """Get compiled graph without checkpointer.

    Use for unit tests where persistence not needed.
    """
    workflow = create_graph()
    return workflow.compile()
```
  </action>
  <verify>python -c "from src.graph.graph import create_graph; g = create_graph(); print('graph ok')"</verify>
  <done>Graph with extraction node, loop guards, and validation placeholder</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.graph import create_graph"` succeeds
- [ ] `python -c "from src.graph.nodes import extraction_node"` succeeds
- [ ] Graph compiles without errors
- [ ] MAX_STEPS=10 enforced in should_continue
- [ ] No import errors
</verification>

<success_criteria>

- All tasks completed
- Graph has extraction node with patch-style updates
- Loop protection via step_count and MAX_STEPS
- Validation placeholder ready for 05-03
- Graph can compile with or without checkpointer
</success_criteria>

<output>
After completion, create `.planning/phases/05-agent-core/05-02-SUMMARY.md`
</output>
